# Qdrant (local on-disk storage)
# - Use a filesystem path to store Qdrant data locally (recommended for dev).
# - You can also set it to an URL (e.g. http://localhost:6333) to use a running Qdrant server.
QDRANT_LOCATION=./qdrant_data

# Alternative name (supported as fallback)
# QDRANT_PATH=./qdrant_data

# Optional (when using Qdrant Cloud / remote server)
# QDRANT_API_KEY=

# Collection name used by `rag/chunk_store.py`
QDRANT_COLLECTION=rag_chunks

# Embedding model used by chunk_store/retrieval
RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Reranker model used by `rag/executor.py` (CrossEncoder)
RAG_RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# How many candidates to pull from Qdrant and how many to show after rerank
RAG_RETRIEVAL_LIMIT=20
RAG_RERANK_LIMIT=10

# Prompt chunk selection (used by `rag/executor.py`)
# - Uses reranked rows with rerank_score >= RAG_RERANK_MIN_SCORE when available.
# - Falls back to top rows to ensure prompt isn't empty.
RAG_RERANK_MIN_SCORE=0.0
RAG_PROMPT_MIN_ROWS=3

# Offline / model download control (Hugging Face / transformers)
# - Set to 1 to force local-only model loading (no network).
# - Leave empty/0 to allow downloading the model if it isn't cached.
HF_HUB_OFFLINE=0
TRANSFORMERS_OFFLINE=0
RAG_OFFLINE=0

# OpenAI (used by `rag/llm.py`)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_TIMEOUT_SECONDS=60
